{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd419c71",
   "metadata": {},
   "source": [
    "# K-Means Implementation: From Scratch to Production\n",
    "\n",
    "In this notebook, we'll:\n",
    "\n",
    "1. Implement K-Means from scratch using pure NumPy\n",
    "2. Compare with scikit-learn's implementation\n",
    "3. Understand K-Means++ initialization\n",
    "4. Benchmark performance and accuracy\n",
    "5. Apply elbow method and silhouette analysis\n",
    "\n",
    "Let's build K-Means step by step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abfef24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans as SklearnKMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import time\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Import our custom implementation\n",
    "from kmeans import KMeans\n",
    "from utils import plot_clusters_2d, plot_elbow, plot_silhouette_scores\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('Set2')\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cafe1d6",
   "metadata": {},
   "source": [
    "## 1. Create Sample Data\n",
    "\n",
    "Let's generate synthetic data with known clusters for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbfc955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "X, y_true = make_blobs(\n",
    "    n_samples=500,\n",
    "    centers=4,\n",
    "    n_features=2,\n",
    "    cluster_std=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Number of samples: {X.shape[0]}\")\n",
    "print(f\"Number of features: {X.shape[1]}\")\n",
    "\n",
    "# Visualize the raw data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X[:, 0], X[:, 1], s=50, alpha=0.6, edgecolors='black', linewidths=0.5)\n",
    "plt.title('Unlabeled Data', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Feature 1', fontsize=12)\n",
    "plt.ylabel('Feature 2', fontsize=12)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e067b7",
   "metadata": {},
   "source": [
    "## 2. Our From-Scratch Implementation\n",
    "\n",
    "We've already implemented a complete K-Means class in `src/kmeans.py`. Let's test it!\n",
    "\n",
    "### Key Features of Our Implementation:\n",
    "- **K-Means++ initialization:** Smart centroid selection for better convergence\n",
    "- **Convergence detection:** Stops when centroids stabilize\n",
    "- **Inertia tracking:** Measures cluster quality (WCSS)\n",
    "- **Pure NumPy:** No external dependencies (except NumPy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83b5342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our custom K-Means\n",
    "kmeans_custom = KMeans(\n",
    "    n_clusters=4,\n",
    "    max_iters=300,\n",
    "    init='kmeans++',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start_time = time.time()\n",
    "kmeans_custom.fit(X)\n",
    "custom_time = time.time() - start_time\n",
    "\n",
    "print(f\"‚úÖ Custom K-Means completed!\")\n",
    "print(f\"   Number of iterations: {kmeans_custom.n_iter_}\")\n",
    "print(f\"   Final inertia (WCSS): {kmeans_custom.inertia_:.2f}\")\n",
    "print(f\"   Execution time: {custom_time*1000:.2f} ms\")\n",
    "print(f\"   Cluster centers shape: {kmeans_custom.cluster_centers_.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1465d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results with Plotly\n",
    "fig = plot_clusters_2d(\n",
    "    X,\n",
    "    kmeans_custom.labels_,\n",
    "    kmeans_custom.cluster_centers_,\n",
    "    title=\"Custom K-Means Implementation Results\",\n",
    "    feature_names=['Feature 1', 'Feature 2']\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "print(\"üé® Interactive plot: Hover to see details, zoom, pan, and export!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48988516",
   "metadata": {},
   "source": [
    "## 3. Compare with scikit-learn\n",
    "\n",
    "Let's benchmark our implementation against the production-ready sklearn version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a446a6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize sklearn K-Means\n",
    "kmeans_sklearn = SklearnKMeans(\n",
    "    n_clusters=4,\n",
    "    init='k-means++',\n",
    "    max_iter=300,\n",
    "    n_init=1,  # Single run for fair comparison\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "start_time = time.time()\n",
    "kmeans_sklearn.fit(X)\n",
    "sklearn_time = time.time() - start_time\n",
    "\n",
    "print(f\"‚úÖ sklearn K-Means completed!\")\n",
    "print(f\"   Number of iterations: {kmeans_sklearn.n_iter_}\")\n",
    "print(f\"   Final inertia (WCSS): {kmeans_sklearn.inertia_:.2f}\")\n",
    "print(f\"   Execution time: {sklearn_time*1000:.2f} ms\")\n",
    "print(f\"   Cluster centers shape: {kmeans_sklearn.cluster_centers_.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b588434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side-by-side comparison\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Metric': ['Inertia (WCSS)', 'Iterations', 'Time (ms)', 'Time Ratio'],\n",
    "    'Custom Implementation': [\n",
    "        f\"{kmeans_custom.inertia_:.2f}\",\n",
    "        kmeans_custom.n_iter_,\n",
    "        f\"{custom_time*1000:.2f}\",\n",
    "        \"1.0x (baseline)\"\n",
    "    ],\n",
    "    'scikit-learn': [\n",
    "        f\"{kmeans_sklearn.inertia_:.2f}\",\n",
    "        kmeans_sklearn.n_iter_,\n",
    "        f\"{sklearn_time*1000:.2f}\",\n",
    "        f\"{sklearn_time/custom_time:.2f}x\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\nüìä Performance Comparison:\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"\\nüí° Note: sklearn is typically faster due to optimized C implementations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18589e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize both results side by side\n",
    "from utils import create_comparison_figure\n",
    "\n",
    "labels_dict = {\n",
    "    'Custom K-Means': kmeans_custom.labels_,\n",
    "    'sklearn K-Means': kmeans_sklearn.labels_\n",
    "}\n",
    "\n",
    "centroids_dict = {\n",
    "    'Custom K-Means': kmeans_custom.cluster_centers_,\n",
    "    'sklearn K-Means': kmeans_sklearn.cluster_centers_\n",
    "}\n",
    "\n",
    "fig = create_comparison_figure(\n",
    "    X,\n",
    "    labels_dict,\n",
    "    centroids_dict,\n",
    "    title=\"Custom vs sklearn K-Means Comparison\"\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "print(\"Both implementations produce nearly identical results! ‚ú®\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d655924e",
   "metadata": {},
   "source": [
    "## 4. K-Means++ vs Random Initialization\n",
    "\n",
    "**K-Means++** is a smart initialization method that:\n",
    "1. Chooses first centroid randomly\n",
    "2. For each subsequent centroid, chooses points far from existing centroids (with probability proportional to distance¬≤)\n",
    "\n",
    "**Why it matters:** Better initialization ‚Üí faster convergence, better final clusters\n",
    "\n",
    "Let's compare random vs K-Means++ initialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d253fd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random initialization\n",
    "kmeans_random = KMeans(n_clusters=4, init='random', random_state=42)\n",
    "kmeans_random.fit(X)\n",
    "\n",
    "# K-Means++ initialization\n",
    "kmeans_plusplus = KMeans(n_clusters=4, init='kmeans++', random_state=42)\n",
    "kmeans_plusplus.fit(X)\n",
    "\n",
    "print(\"Comparison: Random vs K-Means++ Initialization\\n\")\n",
    "print(f\"Random Init:\")\n",
    "print(f\"  Iterations: {kmeans_random.n_iter_}\")\n",
    "print(f\"  Final inertia: {kmeans_random.inertia_:.2f}\\n\")\n",
    "\n",
    "print(f\"K-Means++ Init:\")\n",
    "print(f\"  Iterations: {kmeans_plusplus.n_iter_}\")\n",
    "print(f\"  Final inertia: {kmeans_plusplus.inertia_:.2f}\\n\")\n",
    "\n",
    "improvement = (1 - kmeans_plusplus.inertia_ / kmeans_random.inertia_) * 100\n",
    "print(f\"üìà K-Means++ achieved {improvement:.1f}% better clustering (lower inertia)\")\n",
    "print(f\"‚ö° K-Means++ converged in {kmeans_random.n_iter_ - kmeans_plusplus.n_iter_} fewer iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d24e0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the difference\n",
    "labels_dict_init = {\n",
    "    'Random Initialization': kmeans_random.labels_,\n",
    "    'K-Means++ Initialization': kmeans_plusplus.labels_\n",
    "}\n",
    "\n",
    "centroids_dict_init = {\n",
    "    'Random Initialization': kmeans_random.cluster_centers_,\n",
    "    'K-Means++ Initialization': kmeans_plusplus.cluster_centers_\n",
    "}\n",
    "\n",
    "fig = create_comparison_figure(\n",
    "    X,\n",
    "    labels_dict_init,\n",
    "    centroids_dict_init,\n",
    "    title=\"Impact of Initialization Method\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5aaac1",
   "metadata": {},
   "source": [
    "## 5. Elbow Method Implementation\n",
    "\n",
    "Now let's use our implementation to find the optimal K:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836b5c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different values of K\n",
    "K_range = range(1, 11)\n",
    "inertias = []\n",
    "\n",
    "print(\"Running K-Means for different K values...\")\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    print(f\"  K={k}: inertia={kmeans.inertia_:.2f}\")\n",
    "\n",
    "print(\"\\n‚úÖ Elbow analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a21a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the elbow curve using our utility function\n",
    "fig = plot_elbow(K_range, inertias, title=\"Elbow Method: Finding Optimal K\")\n",
    "fig.show()\n",
    "\n",
    "print(\"üìç Look for the 'elbow' where the curve bends sharply.\")\n",
    "print(\"Based on the plot, K=4 appears to be optimal!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd38da4",
   "metadata": {},
   "source": [
    "## 6. Silhouette Analysis\n",
    "\n",
    "Let's complement the elbow method with silhouette scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03b8af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate silhouette scores\n",
    "K_range_sil = range(2, 11)  # Need at least 2 clusters for silhouette\n",
    "silhouette_scores = []\n",
    "\n",
    "print(\"Calculating silhouette scores...\")\n",
    "for k in K_range_sil:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    labels = kmeans.fit_predict(X)\n",
    "    score = silhouette_score(X, labels)\n",
    "    silhouette_scores.append(score)\n",
    "    print(f\"  K={k}: silhouette score={score:.3f}\")\n",
    "\n",
    "print(\"\\n‚úÖ Silhouette analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38690ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot silhouette scores\n",
    "fig = plot_silhouette_scores(\n",
    "    K_range_sil,\n",
    "    silhouette_scores,\n",
    "    title=\"Silhouette Score Analysis\"\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "best_k_idx = np.argmax(silhouette_scores)\n",
    "best_k = list(K_range_sil)[best_k_idx]\n",
    "print(f\"\\nüèÜ Best K according to silhouette score: {best_k}\")\n",
    "print(f\"Silhouette score: {silhouette_scores[best_k_idx]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ef1cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed silhouette analysis for K=4\n",
    "from utils import plot_silhouette_analysis\n",
    "\n",
    "kmeans_final = KMeans(n_clusters=4, random_state=42)\n",
    "labels_final = kmeans_final.fit_predict(X)\n",
    "\n",
    "fig = plot_silhouette_analysis(X, labels_final, n_clusters=4)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Silhouette plot interpretation:\")\n",
    "print(\"  ‚Ä¢ Wider bars = better-defined clusters\")\n",
    "print(\"  ‚Ä¢ Values close to 1 = well-clustered points\")\n",
    "print(\"  ‚Ä¢ Values near 0 or negative = points on cluster boundaries or misclassified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca22cf95",
   "metadata": {},
   "source": [
    "## 7. Prediction on New Data\n",
    "\n",
    "Once we've fit K-Means, we can assign new points to existing clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b45603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new test points\n",
    "X_new = np.array([\n",
    "    [0, 0],      # Point near cluster 1\n",
    "    [10, 10],    # Point near cluster 2\n",
    "    [-8, -8],    # Point near cluster 3\n",
    "    [5, -8]      # Point near cluster 4\n",
    "])\n",
    "\n",
    "# Predict cluster assignments\n",
    "predictions = kmeans_final.predict(X_new)\n",
    "\n",
    "print(\"New points and their predicted clusters:\\n\")\n",
    "for i, (point, cluster) in enumerate(zip(X_new, predictions)):\n",
    "    print(f\"  Point {i+1}: {point} ‚Üí Cluster {cluster}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21918724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "fig = plot_clusters_2d(\n",
    "    X,\n",
    "    labels_final,\n",
    "    kmeans_final.cluster_centers_,\n",
    "    title=\"K-Means with New Point Predictions\",\n",
    "    feature_names=['Feature 1', 'Feature 2']\n",
    ")\n",
    "\n",
    "# Add new points\n",
    "colors_new = px.colors.qualitative.Set2\n",
    "for i, (point, cluster) in enumerate(zip(X_new, predictions)):\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[point[0]],\n",
    "        y=[point[1]],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=20,\n",
    "            color=colors_new[cluster],\n",
    "            symbol='star',\n",
    "            line=dict(width=2, color='black')\n",
    "        ),\n",
    "        name=f'New Point {i+1} (Cluster {cluster})',\n",
    "        showlegend=True\n",
    "    ))\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"‚≠ê New points shown as stars, colored by their predicted cluster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1518d878",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we:\n",
    "\n",
    "1. ‚úÖ **Implemented K-Means from scratch** in pure NumPy with K-Means++ initialization\n",
    "2. ‚úÖ **Compared with sklearn** and found nearly identical results\n",
    "3. ‚úÖ **Demonstrated K-Means++** superiority over random initialization\n",
    "4. ‚úÖ **Applied the elbow method** to find optimal K\n",
    "5. ‚úÖ **Used silhouette analysis** to validate cluster quality\n",
    "6. ‚úÖ **Made predictions** on new data points\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- **K-Means++ initialization** is essential for good results\n",
    "- **Combine multiple methods** (elbow + silhouette) to choose K\n",
    "- **Our implementation** is correct but sklearn is faster (optimized C code)\n",
    "- **Silhouette scores** provide quantitative cluster quality assessment\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "In **Notebook 03**, we'll apply K-Means to real-world problems:\n",
    "- Customer segmentation for targeted marketing\n",
    "- Image compression using color clustering\n",
    "- Business insights and actionable recommendations\n",
    "\n",
    "---\n",
    "\n",
    "**Ready for real data?** ‚Üí [03_real_world.ipynb](03_real_world.ipynb)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
